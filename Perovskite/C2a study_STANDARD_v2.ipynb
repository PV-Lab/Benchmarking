{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Liangqiaohao/Desktop/PV Lab/2020/March/Learning project/C2a\n"
     ]
    }
   ],
   "source": [
    "cd /Users/Liangqiaohao/Desktop/PV Lab/2020/March/Learning project/C2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import GPyOpt\n",
    "import GPy\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.tri as tri\n",
    "\n",
    "import ternary\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "from collections import Counter\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "import pyDOE\n",
    "import random\n",
    "from scipy.stats import norm\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_excel(r'/Users/Liangqiaohao/Desktop/PV Lab/2020/March/Learning project/C2a/C2a learning study.xlsx')\n",
    "X = dataset.iloc[:,0:5]\n",
    "\n",
    "X_run = X.groupby(['CsPbI', 'MAPbI', 'FAPbI'])['Instability index'].agg(lambda x: x.unique().mean())\n",
    "X_run = (X_run.to_frame()).reset_index()\n",
    "\n",
    "materials = ['CsPbI', 'MAPbI', 'FAPbI']\n",
    "X_feature = X_run[['CsPbI', 'MAPbI', 'FAPbI']].values\n",
    "y = np.array(X_run['Instability index'].values)\n",
    "\n",
    "X_Cs = np.array(X_run['CsPbI'].values)\n",
    "X_FA = np.array(X_run['FAPbI'].values)\n",
    "X_MA = np.array(X_run['MAPbI'].values)\n",
    "\n",
    "raw_mean = np.mean(y)\n",
    "raw_std = np.std(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = (y - raw_mean) / raw_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total 94 pts\n",
    "n_initial = 2\n",
    "n_test = int(math.ceil(len(y) * 0.30))\n",
    "n_top = int(math.ceil(len(y) * 0.05))\n",
    "\n",
    "top_indices = list(X_run.sort_values('Instability index').head(n_top).index)\n",
    "\n",
    "# seed_list = [74,28,861,1526,2,151,19617,7,33,47302,66,552,671,25,1368,850,71,2148,2621,26, 6, 294, 9256, 851, 666]\n",
    "# # 20\n",
    "\n",
    "seed_list = [5, 892, 91, 2345, 391, 77, 223, 8258, 16, 3, 84,7646,6207,4530,8206,6260,2342,3112,5187,2737,8979,4018,8223,1678,9481,2232,\n",
    "             461,7694,6091, 3189,2480,9106,1316,8500,2531,5329,9872,1388,8805,2726,119,3416,7747,3927,138,1488,232,4564,3492,9841]\n",
    "# 50\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EI(X, model, y_best):\n",
    "#     xi = 0.01\n",
    "    X = X.reshape([1,X_feature.shape[1]])\n",
    "    \n",
    "    mean, std = model.predict(X)[0][0][0], model.predict(X)[1][0][0]\n",
    "\n",
    "    z = (y_best - mean)/std\n",
    "    return (y_best - mean) * norm.cdf(z) + std * norm.pdf(z)\n",
    "\n",
    "def LCB(X, model):\n",
    "    X = X.reshape([1,X_feature.shape[1]])\n",
    "    \n",
    "    mean, std = model.predict(X)[0][0][0], model.predict(X)[1][0][0]\n",
    "    \n",
    "    return 1 * std - 1 * mean\n",
    "\n",
    "def MPI(X, model, y_best):\n",
    "    X = X.reshape([1,X_feature.shape[1]])\n",
    "    \n",
    "    mean, std = model.predict(X)[0][0][0], model.predict(X)[1][0][0]\n",
    "    \n",
    "    z = (y_best - mean)/std\n",
    "    return norm.cdf(z)\n",
    "\n",
    "def calc_MAE(test_index, SL_model):\n",
    "    SL_mae = 0\n",
    "    \n",
    "    for index in test_index:\n",
    "        X_test = X_feature[index]\n",
    "        y_test = y[index]\n",
    "        \n",
    "        X_test = X_test.reshape([1,X_feature.shape[1]])\n",
    "        \n",
    "        SL_mean, SL_std = SL_model.predict(X_test)[0][0][0], SL_model.predict(X_test)[1][0][0]\n",
    "        \n",
    "        sl_mae = (y_test - SL_mean)**2 / len(test_index)\n",
    "        SL_mae += sl_mae       \n",
    "    \n",
    "    return SL_mae\n",
    "\n",
    "def TopPercent(top_indices, index_):\n",
    "    how_many = 0\n",
    "    for i in index_:\n",
    "        if i in top_indices:\n",
    "            how_many += 1\n",
    "    return how_many\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARD_ = False\n",
    "\n",
    "Bias_kernel = GPy.kern.Bias(X_feature.shape[1], variance=1.)\n",
    "\n",
    "Matern52_kernel = GPy.kern.Matern52(X_feature.shape[1], variance=1., ARD=ARD_) + Bias_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing seed = 0\n",
      "Finished seed\n",
      "initializing seed = 1\n",
      "Finished seed\n",
      "initializing seed = 2\n",
      "Finished seed\n",
      "initializing seed = 3\n",
      "Finished seed\n",
      "initializing seed = 4\n",
      "Finished seed\n",
      "initializing seed = 5\n",
      "Finished seed\n",
      "initializing seed = 6\n",
      "Finished seed\n",
      "initializing seed = 7\n",
      "Finished seed\n",
      "initializing seed = 8\n",
      "Finished seed\n",
      "initializing seed = 9\n",
      "Finished seed\n",
      "initializing seed = 10\n",
      "Finished seed\n",
      "initializing seed = 11\n",
      "Finished seed\n",
      "initializing seed = 12\n",
      "Finished seed\n",
      "initializing seed = 13\n",
      "Finished seed\n",
      "initializing seed = 14\n",
      "Finished seed\n",
      "initializing seed = 15\n",
      "Finished seed\n",
      "initializing seed = 16\n",
      "Finished seed\n",
      "initializing seed = 17\n",
      "Finished seed\n",
      "initializing seed = 18\n",
      "Finished seed\n",
      "initializing seed = 19\n",
      "Finished seed\n",
      "initializing seed = 20\n",
      "Finished seed\n",
      "initializing seed = 21\n",
      "Finished seed\n",
      "initializing seed = 22\n",
      "Finished seed\n",
      "initializing seed = 23\n",
      "Finished seed\n",
      "initializing seed = 24\n",
      "Finished seed\n",
      "initializing seed = 25\n",
      "Finished seed\n",
      "initializing seed = 26\n",
      "Finished seed\n",
      "initializing seed = 27\n",
      "Finished seed\n",
      "initializing seed = 28\n",
      "Finished seed\n",
      "initializing seed = 29\n",
      "Finished seed\n",
      "initializing seed = 30\n",
      "Finished seed\n",
      "initializing seed = 31\n",
      "Finished seed\n",
      "initializing seed = 32\n",
      "Finished seed\n",
      "initializing seed = 33\n",
      "Finished seed\n",
      "initializing seed = 34\n",
      "Finished seed\n",
      "initializing seed = 35\n",
      "Finished seed\n",
      "initializing seed = 36\n",
      "Finished seed\n",
      "initializing seed = 37\n",
      "Finished seed\n",
      "initializing seed = 38\n",
      "Finished seed\n",
      "initializing seed = 39\n",
      "Finished seed\n",
      "initializing seed = 40\n",
      "Finished seed\n",
      "initializing seed = 41\n",
      "Finished seed\n",
      "initializing seed = 42\n",
      "Finished seed\n",
      "initializing seed = 43\n",
      "Finished seed\n",
      "initializing seed = 44\n",
      "Finished seed\n",
      "initializing seed = 45\n",
      "Finished seed\n",
      "initializing seed = 46\n",
      "Finished seed\n",
      "initializing seed = 47\n",
      "Finished seed\n",
      "initializing seed = 48\n",
      "Finished seed\n",
      "initializing seed = 49\n",
      "Finished seed\n"
     ]
    }
   ],
   "source": [
    "index_collection = []\n",
    "X_collection = []\n",
    "y_collection = []\n",
    "TopPercent_collection = []\n",
    "MAE_collection = []\n",
    "\n",
    "\n",
    "for s in seed_list:\n",
    "    print('initializing seed = ' +str(seed_list.index(s)))\n",
    "    random.seed(s)\n",
    "    \n",
    "    indices = list(np.arange(len(X_run)))\n",
    "    \n",
    "    \n",
    "    X_top = []\n",
    "    y_top = []\n",
    "    for i in top_indices:\n",
    "        X_top.append(X_feature[i])\n",
    "        y_top.append(y[i])\n",
    "        \n",
    "    index_learn = indices.copy()\n",
    "    \n",
    "    index_ = random.sample(index_learn, n_initial)\n",
    "    X_ = []\n",
    "    y_ = []\n",
    "    TopPercent_ = []\n",
    "    MAE_ = []\n",
    "    for i in index_:\n",
    "        X_.append(X_feature[i])\n",
    "        y_.append(y[i])\n",
    "        index_learn.remove(i)\n",
    "        \n",
    "    index_mae = indices.copy()\n",
    "    \n",
    "    test_index = random.sample(index_mae, n_test)\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for i in test_index:\n",
    "        X_test.append(X_feature[i])\n",
    "        y_test.append(y[i])\n",
    "        index_mae.remove(i)\n",
    "        \n",
    "    X_full = []\n",
    "    y_full = []    \n",
    "    for i in index_mae:\n",
    "        X_full.append(X_feature[i])\n",
    "        y_full.append(y[i])\n",
    "        \n",
    "    \n",
    "    \n",
    "    assert len(indices) == len(X_full) + len(X_test)\n",
    "    \n",
    "#     GP_full = GPy.models.GPRegression(X = np.array(X_full), \n",
    "#                                       Y = np.array([[i] for i in y_full]), \n",
    "#                                       kernel= Matern52_kernel,\n",
    "#                                       noise_var = 0.01\n",
    "#                                       )\n",
    "\n",
    "#     GP_full.optimize_restarts(num_restarts=10,\n",
    "#                               parallel = True,\n",
    "#                               robust = True,\n",
    "#                               optimizer = 'bfgs',\n",
    "#                               max_iters=100,\n",
    "#                               verbose = False)\n",
    "    \n",
    "    for i in np.arange(len(index_learn)):\n",
    "        \n",
    "        y_best = np.min(y_)\n",
    "        \n",
    "        GP_learn = GPy.models.GPRegression(X = np.array(X_), \n",
    "                                           Y = np.array([[i] for i in y_]), \n",
    "                                           kernel= Matern52_kernel,\n",
    "                                           noise_var = 0.01\n",
    "                                          )\n",
    "\n",
    "        GP_learn.optimize_restarts(num_restarts=10,\n",
    "                                   parallel = True,\n",
    "                                   robust = True,\n",
    "                                   optimizer = 'bfgs',\n",
    "                                   max_iters=100,\n",
    "                                   verbose = False)\n",
    "        \n",
    "        next_index = None\n",
    "        max_ac = -10**10\n",
    "        for j in index_learn:\n",
    "            X_j = X_feature[j]\n",
    "            y_j = y[j]\n",
    "            \n",
    "            ac_value = EI(X_j, GP_learn, y_best)\n",
    "            \n",
    "            if max_ac <= ac_value:\n",
    "                max_ac = ac_value\n",
    "                next_index = j\n",
    "                \n",
    "        X_.append(X_feature[next_index])\n",
    "        y_.append(y[next_index])\n",
    "        index_learn.remove(next_index)\n",
    "        index_.append(next_index)\n",
    "        \n",
    "        \n",
    "        mae_ = calc_MAE(test_index, GP_learn)\n",
    "        MAE_.append(mae_)\n",
    "        TopPercent_.append(TopPercent(top_indices, index_))\n",
    "        \n",
    "\n",
    "\n",
    "    index_collection.append(index_)\n",
    "    X_collection.append(X_)\n",
    "    y_collection.append(y_)\n",
    "    TopPercent_collection.append(TopPercent_)\n",
    "    MAE_collection.append(MAE_)\n",
    "    \n",
    "    print('Finished seed')\n",
    "    \n",
    "    \n",
    "master = np.array([index_collection, X_collection, y_collection, TopPercent_collection, MAE_collection])\n",
    "np.save('STANDARD_GP_EI_master', master)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing seed = 0\n",
      "Finished seed\n",
      "initializing seed = 1\n",
      "Finished seed\n",
      "initializing seed = 2\n",
      "Finished seed\n",
      "initializing seed = 3\n",
      "Finished seed\n",
      "initializing seed = 4\n",
      "Finished seed\n",
      "initializing seed = 5\n",
      "Finished seed\n",
      "initializing seed = 6\n",
      "Finished seed\n",
      "initializing seed = 7\n",
      "Finished seed\n",
      "initializing seed = 8\n",
      "Finished seed\n",
      "initializing seed = 9\n",
      "Finished seed\n",
      "initializing seed = 10\n",
      "Finished seed\n",
      "initializing seed = 11\n",
      "Finished seed\n",
      "initializing seed = 12\n",
      "Finished seed\n",
      "initializing seed = 13\n",
      "Finished seed\n",
      "initializing seed = 14\n",
      "Finished seed\n",
      "initializing seed = 15\n",
      "Finished seed\n",
      "initializing seed = 16\n",
      "Finished seed\n",
      "initializing seed = 17\n",
      "Finished seed\n",
      "initializing seed = 18\n",
      "Finished seed\n",
      "initializing seed = 19\n",
      "Finished seed\n",
      "initializing seed = 20\n",
      "Finished seed\n",
      "initializing seed = 21\n",
      "Finished seed\n",
      "initializing seed = 22\n",
      "Finished seed\n",
      "initializing seed = 23\n",
      "Finished seed\n",
      "initializing seed = 24\n",
      "Finished seed\n",
      "initializing seed = 25\n",
      "Finished seed\n",
      "initializing seed = 26\n",
      "Finished seed\n",
      "initializing seed = 27\n",
      "Finished seed\n",
      "initializing seed = 28\n",
      "Finished seed\n",
      "initializing seed = 29\n",
      "Finished seed\n",
      "initializing seed = 30\n",
      "Finished seed\n",
      "initializing seed = 31\n",
      "Finished seed\n",
      "initializing seed = 32\n",
      "Finished seed\n",
      "initializing seed = 33\n",
      "Finished seed\n",
      "initializing seed = 34\n",
      "Finished seed\n",
      "initializing seed = 35\n",
      "Finished seed\n",
      "initializing seed = 36\n",
      "Finished seed\n",
      "initializing seed = 37\n",
      "Finished seed\n",
      "initializing seed = 38\n",
      "Finished seed\n",
      "initializing seed = 39\n",
      "Finished seed\n",
      "initializing seed = 40\n",
      "Finished seed\n",
      "initializing seed = 41\n",
      "Finished seed\n",
      "initializing seed = 42\n",
      "Finished seed\n",
      "initializing seed = 43\n",
      "Finished seed\n",
      "initializing seed = 44\n",
      "Finished seed\n",
      "initializing seed = 45\n",
      "Finished seed\n",
      "initializing seed = 46\n",
      "Finished seed\n",
      "initializing seed = 47\n",
      "Finished seed\n",
      "initializing seed = 48\n",
      "Finished seed\n",
      "initializing seed = 49\n",
      "Finished seed\n"
     ]
    }
   ],
   "source": [
    "index_collection = []\n",
    "X_collection = []\n",
    "y_collection = []\n",
    "TopPercent_collection = []\n",
    "MAE_collection = []\n",
    "\n",
    "\n",
    "for s in seed_list:\n",
    "    print('initializing seed = ' +str(seed_list.index(s)))\n",
    "    random.seed(s)\n",
    "    \n",
    "    indices = list(np.arange(len(X_run)))\n",
    "    \n",
    "    \n",
    "    X_top = []\n",
    "    y_top = []\n",
    "    for i in top_indices:\n",
    "        X_top.append(X_feature[i])\n",
    "        y_top.append(y[i])\n",
    "        \n",
    "    index_learn = indices.copy()\n",
    "    \n",
    "    index_ = random.sample(index_learn, n_initial)\n",
    "    X_ = []\n",
    "    y_ = []\n",
    "    TopPercent_ = []\n",
    "    MAE_ = []\n",
    "    for i in index_:\n",
    "        X_.append(X_feature[i])\n",
    "        y_.append(y[i])\n",
    "        index_learn.remove(i)\n",
    "        \n",
    "    index_mae = indices.copy()\n",
    "    \n",
    "    test_index = random.sample(index_mae, n_test)\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for i in test_index:\n",
    "        X_test.append(X_feature[i])\n",
    "        y_test.append(y[i])\n",
    "        index_mae.remove(i)\n",
    "        \n",
    "    X_full = []\n",
    "    y_full = []    \n",
    "    for i in index_mae:\n",
    "        X_full.append(X_feature[i])\n",
    "        y_full.append(y[i])\n",
    "        \n",
    "    \n",
    "    \n",
    "    assert len(indices) == len(X_full) + len(X_test)\n",
    "    \n",
    "#     GP_full = GPy.models.GPRegression(X = np.array(X_full), \n",
    "#                                       Y = np.array([[i] for i in y_full]), \n",
    "#                                       kernel= Matern52_kernel,\n",
    "#                                       noise_var = 0.01\n",
    "#                                       )\n",
    "\n",
    "#     GP_full.optimize_restarts(num_restarts=10,\n",
    "#                               parallel = True,\n",
    "#                               robust = True,\n",
    "#                               optimizer = 'bfgs',\n",
    "#                               max_iters=100,\n",
    "#                               verbose = False)\n",
    "    \n",
    "    for i in np.arange(len(index_learn)):\n",
    "        \n",
    "        y_best = np.min(y_)\n",
    "        \n",
    "        GP_learn = GPy.models.GPRegression(X = np.array(X_), \n",
    "                                           Y = np.array([[i] for i in y_]), \n",
    "                                           kernel= Matern52_kernel,\n",
    "                                           noise_var = 0.01\n",
    "                                          )\n",
    "\n",
    "        GP_learn.optimize_restarts(num_restarts=10,\n",
    "                                   parallel = True,\n",
    "                                   robust = True,\n",
    "                                   optimizer = 'bfgs',\n",
    "                                   max_iters=100,\n",
    "                                   verbose = False)\n",
    "        \n",
    "        next_index = None\n",
    "        max_ac = -10**10\n",
    "        for j in index_learn:\n",
    "            X_j = X_feature[j]\n",
    "            y_j = y[j]\n",
    "            \n",
    "            ac_value = LCB(X_j, GP_learn)\n",
    "            \n",
    "            if max_ac <= ac_value:\n",
    "                max_ac = ac_value\n",
    "                next_index = j\n",
    "                \n",
    "        X_.append(X_feature[next_index])\n",
    "        y_.append(y[next_index])\n",
    "        index_learn.remove(next_index)\n",
    "        index_.append(next_index)\n",
    "        \n",
    "        \n",
    "        mae_ = calc_MAE(test_index, GP_learn)\n",
    "        MAE_.append(mae_)\n",
    "        TopPercent_.append(TopPercent(top_indices, index_))\n",
    "        \n",
    "\n",
    "\n",
    "    index_collection.append(index_)\n",
    "    X_collection.append(X_)\n",
    "    y_collection.append(y_)\n",
    "    TopPercent_collection.append(TopPercent_)\n",
    "    MAE_collection.append(MAE_)\n",
    "    \n",
    "    print('Finished seed')\n",
    "    \n",
    "    \n",
    "master = np.array([index_collection, X_collection, y_collection, TopPercent_collection, MAE_collection])\n",
    "np.save('STANDARD_GP_LCB11_master', master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing seed = 0\n",
      "Finished seed\n",
      "initializing seed = 1\n",
      "Finished seed\n",
      "initializing seed = 2\n",
      "Finished seed\n",
      "initializing seed = 3\n",
      "Finished seed\n",
      "initializing seed = 4\n",
      "Finished seed\n",
      "initializing seed = 5\n",
      "Finished seed\n",
      "initializing seed = 6\n",
      "Finished seed\n",
      "initializing seed = 7\n",
      "Finished seed\n",
      "initializing seed = 8\n",
      "Finished seed\n",
      "initializing seed = 9\n",
      "Finished seed\n",
      "initializing seed = 10\n",
      "Finished seed\n",
      "initializing seed = 11\n",
      "Finished seed\n",
      "initializing seed = 12\n",
      "Finished seed\n",
      "initializing seed = 13\n",
      "Finished seed\n",
      "initializing seed = 14\n",
      "Finished seed\n",
      "initializing seed = 15\n",
      "Finished seed\n",
      "initializing seed = 16\n",
      "Finished seed\n",
      "initializing seed = 17\n",
      "Finished seed\n",
      "initializing seed = 18\n",
      "Finished seed\n",
      "initializing seed = 19\n",
      "Finished seed\n",
      "initializing seed = 20\n",
      "Finished seed\n",
      "initializing seed = 21\n",
      "Finished seed\n",
      "initializing seed = 22\n",
      "Finished seed\n",
      "initializing seed = 23\n",
      "Finished seed\n",
      "initializing seed = 24\n",
      "Finished seed\n"
     ]
    }
   ],
   "source": [
    "# random sampling\n",
    "index_collection = []\n",
    "X_collection = []\n",
    "y_collection = []\n",
    "TopPercent_collection = []\n",
    "MAE_collection = []\n",
    "\n",
    "\n",
    "for s in seed_list:\n",
    "    print('initializing seed = ' +str(seed_list.index(s)))\n",
    "    random.seed(s)\n",
    "    \n",
    "    indices = list(np.arange(len(X_run)))\n",
    "    \n",
    "    \n",
    "    X_top = []\n",
    "    y_top = []\n",
    "    for i in top_indices:\n",
    "        X_top.append(X_feature[i])\n",
    "        y_top.append(y[i])\n",
    "        \n",
    "    index_learn = indices.copy()\n",
    "    \n",
    "    index_ = random.sample(index_learn, n_initial)\n",
    "    X_ = []\n",
    "    y_ = []\n",
    "    TopPercent_ = []\n",
    "    MAE_ = []\n",
    "    for i in index_:\n",
    "        X_.append(X_feature[i])\n",
    "        y_.append(y[i])\n",
    "        index_learn.remove(i)\n",
    "        \n",
    "    index_mae = indices.copy()\n",
    "    \n",
    "    test_index = random.sample(index_mae, n_test)\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for i in test_index:\n",
    "        X_test.append(X_feature[i])\n",
    "        y_test.append(y[i])\n",
    "        index_mae.remove(i)\n",
    "        \n",
    "#     X_full = []\n",
    "#     y_full = []    \n",
    "#     for i in index_mae:\n",
    "#         X_full.append(X_feature[i])\n",
    "#         y_full.append(y[i])\n",
    "        \n",
    "    \n",
    "    \n",
    "#     assert len(indices) == len(X_full) + len(X_test)\n",
    "    \n",
    "#     GP_full = GPy.models.GPRegression(X = np.array(X_full), \n",
    "#                                       Y = np.array([[i] for i in y_full]), \n",
    "#                                       kernel= Matern52_kernel,\n",
    "#                                       noise_var = 0.01\n",
    "#                                       )\n",
    "\n",
    "#     GP_full.optimize_restarts(num_restarts=10,\n",
    "#                               parallel = True,\n",
    "#                               robust = True,\n",
    "#                               optimizer = 'bfgs',\n",
    "#                               max_iters=100,\n",
    "#                               verbose = False)\n",
    "    \n",
    "    for i in np.arange(len(index_learn)):\n",
    "        \n",
    "        GP_learn = GPy.models.GPRegression(X = np.array(X_), \n",
    "                                           Y = np.array([[i] for i in y_]), \n",
    "                                           kernel= Matern52_kernel,\n",
    "                                           noise_var = 0.01\n",
    "                                          )\n",
    "\n",
    "        GP_learn.optimize_restarts(num_restarts=10,\n",
    "                                   parallel = True,\n",
    "                                   robust = True,\n",
    "                                   optimizer = 'bfgs',\n",
    "                                   max_iters=100,\n",
    "                                   verbose = False)\n",
    "        \n",
    "        \n",
    "        next_index = (random.sample(index_learn, 1))[0]\n",
    "                \n",
    "        X_.append(X_feature[next_index])\n",
    "        y_.append(y[next_index])\n",
    "        index_learn.remove(next_index)\n",
    "        index_.append(next_index)\n",
    "        \n",
    "        \n",
    "        mae_ = calc_MAE(test_index, GP_learn)\n",
    "        MAE_.append(mae_)\n",
    "        TopPercent_.append(TopPercent(top_indices, index_))\n",
    "        \n",
    "\n",
    "\n",
    "    index_collection.append(index_)\n",
    "    X_collection.append(X_)\n",
    "    y_collection.append(y_)\n",
    "    TopPercent_collection.append(TopPercent_)\n",
    "    MAE_collection.append(MAE_)\n",
    "    \n",
    "    print('Finished seed')\n",
    "    \n",
    "    \n",
    "master = np.array([index_collection, X_collection, y_collection, TopPercent_collection, MAE_collection])\n",
    "np.save('STANDARD_GP_RS_master', master)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing seed = 0\n",
      "Finished seed\n",
      "initializing seed = 1\n",
      "Finished seed\n",
      "initializing seed = 2\n",
      "Finished seed\n",
      "initializing seed = 3\n",
      "Finished seed\n",
      "initializing seed = 4\n",
      "Finished seed\n",
      "initializing seed = 5\n",
      "Finished seed\n",
      "initializing seed = 6\n",
      "Finished seed\n",
      "initializing seed = 7\n",
      "Finished seed\n",
      "initializing seed = 8\n",
      "Finished seed\n",
      "initializing seed = 9\n",
      "Finished seed\n",
      "initializing seed = 10\n",
      "Finished seed\n",
      "initializing seed = 11\n",
      "Finished seed\n",
      "initializing seed = 12\n",
      "Finished seed\n",
      "initializing seed = 13\n",
      "Finished seed\n",
      "initializing seed = 14\n",
      "Finished seed\n",
      "initializing seed = 15\n",
      "Finished seed\n",
      "initializing seed = 16\n",
      "Finished seed\n",
      "initializing seed = 17\n",
      "Finished seed\n",
      "initializing seed = 18\n",
      "Finished seed\n",
      "initializing seed = 19\n",
      "Finished seed\n",
      "initializing seed = 20\n",
      "Finished seed\n",
      "initializing seed = 21\n",
      "Finished seed\n",
      "initializing seed = 22\n",
      "Finished seed\n",
      "initializing seed = 23\n",
      "Finished seed\n",
      "initializing seed = 24\n",
      "Finished seed\n"
     ]
    }
   ],
   "source": [
    "index_collection = []\n",
    "X_collection = []\n",
    "y_collection = []\n",
    "TopPercent_collection = []\n",
    "MAE_collection = []\n",
    "\n",
    "\n",
    "for s in seed_list:\n",
    "    print('initializing seed = ' +str(seed_list.index(s)))\n",
    "    random.seed(s)\n",
    "    \n",
    "    indices = list(np.arange(len(X_run)))\n",
    "    \n",
    "    \n",
    "    X_top = []\n",
    "    y_top = []\n",
    "    for i in top_indices:\n",
    "        X_top.append(X_feature[i])\n",
    "        y_top.append(y[i])\n",
    "        \n",
    "    index_learn = indices.copy()\n",
    "    \n",
    "    index_ = random.sample(index_learn, n_initial)\n",
    "    X_ = []\n",
    "    y_ = []\n",
    "    TopPercent_ = []\n",
    "    MAE_ = []\n",
    "    for i in index_:\n",
    "        X_.append(X_feature[i])\n",
    "        y_.append(y[i])\n",
    "        index_learn.remove(i)\n",
    "        \n",
    "    index_mae = indices.copy()\n",
    "    \n",
    "    test_index = random.sample(index_mae, n_test)\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for i in test_index:\n",
    "        X_test.append(X_feature[i])\n",
    "        y_test.append(y[i])\n",
    "        index_mae.remove(i)\n",
    "        \n",
    "    X_full = []\n",
    "    y_full = []    \n",
    "    for i in index_mae:\n",
    "        X_full.append(X_feature[i])\n",
    "        y_full.append(y[i])\n",
    "        \n",
    "    \n",
    "    \n",
    "    assert len(indices) == len(X_full) + len(X_test)\n",
    "    \n",
    "#     GP_full = GPy.models.GPRegression(X = np.array(X_full), \n",
    "#                                       Y = np.array([[i] for i in y_full]), \n",
    "#                                       kernel= Matern52_kernel,\n",
    "#                                       noise_var = 0.01\n",
    "#                                       )\n",
    "\n",
    "#     GP_full.optimize_restarts(num_restarts=10,\n",
    "#                               parallel = True,\n",
    "#                               robust = True,\n",
    "#                               optimizer = 'bfgs',\n",
    "#                               max_iters=100,\n",
    "#                               verbose = False)\n",
    "    \n",
    "    for i in np.arange(len(index_learn)):\n",
    "        \n",
    "        y_best = np.min(y_)\n",
    "        \n",
    "        GP_learn = GPy.models.GPRegression(X = np.array(X_), \n",
    "                                           Y = np.array([[i] for i in y_]), \n",
    "                                           kernel= Matern52_kernel,\n",
    "                                           noise_var = 0.01\n",
    "                                          )\n",
    "\n",
    "        GP_learn.optimize_restarts(num_restarts=10,\n",
    "                                   parallel = True,\n",
    "                                   robust = True,\n",
    "                                   optimizer = 'bfgs',\n",
    "                                   max_iters=100,\n",
    "                                   verbose = False)\n",
    "        \n",
    "        next_index = None\n",
    "        max_ac = -10**10\n",
    "        for j in index_learn:\n",
    "            X_j = X_feature[j]\n",
    "            y_j = y[j]\n",
    "            \n",
    "            ac_value = MPI(X_j, GP_learn, y_best)\n",
    "            \n",
    "            if max_ac <= ac_value:\n",
    "                max_ac = ac_value\n",
    "                next_index = j\n",
    "                \n",
    "        X_.append(X_feature[next_index])\n",
    "        y_.append(y[next_index])\n",
    "        index_learn.remove(next_index)\n",
    "        index_.append(next_index)\n",
    "        \n",
    "        \n",
    "        mae_ = calc_MAE(test_index, GP_learn)\n",
    "        MAE_.append(mae_)\n",
    "        TopPercent_.append(TopPercent(top_indices, index_))\n",
    "        \n",
    "\n",
    "\n",
    "    index_collection.append(index_)\n",
    "    X_collection.append(X_)\n",
    "    y_collection.append(y_)\n",
    "    TopPercent_collection.append(TopPercent_)\n",
    "    MAE_collection.append(MAE_)\n",
    "    \n",
    "    print('Finished seed')\n",
    "    \n",
    "    \n",
    "master = np.array([index_collection, X_collection, y_collection, TopPercent_collection, MAE_collection])\n",
    "np.save('STANDARD_GP_MPI_master', master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_est = 10\n",
    "# for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EI(X, RF_model, y_best):\n",
    "\n",
    "    \n",
    "    tree_predictions = []\n",
    "    for j in np.arange(n_est):\n",
    "        tree_predictions.append((RF_model.estimators_[j].predict(np.array([X]))).tolist())\n",
    "    mean = np.mean(np.array(tree_predictions), axis=0)[0]\n",
    "\n",
    "    \n",
    "    std = np.std(np.array(tree_predictions), axis=0)[0]\n",
    "    \n",
    "    z = (y_best - mean)/std\n",
    "    return (y_best - mean) * norm.cdf(z) + std * norm.pdf(z)\n",
    "\n",
    "def LCB(X, RF_model):\n",
    "    \n",
    "    tree_predictions = []\n",
    "    for j in np.arange(n_est):\n",
    "        tree_predictions.append((RF_model.estimators_[j].predict(np.array([X]))).tolist())\n",
    "    mean = np.mean(np.array(tree_predictions), axis=0)[0]\n",
    "\n",
    "    \n",
    "    std = np.std(np.array(tree_predictions), axis=0)[0]\n",
    "\n",
    "    \n",
    "    return 75 * std - 25 * mean\n",
    "\n",
    "def MPI(X, RF_model, y_best):\n",
    "    \n",
    "    tree_predictions = []\n",
    "    for j in np.arange(n_est):\n",
    "        tree_predictions.append((RF_model.estimators_[j].predict(np.array([X]))).tolist())\n",
    "    mean = np.mean(np.array(tree_predictions), axis=0)[0]\n",
    "    \n",
    "    std = np.std(np.array(tree_predictions), axis=0)[0]\n",
    "\n",
    "    \n",
    "    z = (y_best - mean)/std\n",
    "    return norm.cdf(z)\n",
    "\n",
    "\n",
    "def calc_MAE(test_index, RF_model):\n",
    "    RF_mae = 0\n",
    "    for index in test_index:\n",
    "        X_test = X_feature[index]\n",
    "        y_test = y[index]\n",
    "\n",
    "        tree_predictions = []\n",
    "        for j in np.arange(n_est):\n",
    "            tree_predictions.append((RF_model.estimators_[j].predict(np.array([X_test]))).tolist())\n",
    "        mean = np.mean(np.array(tree_predictions), axis=0)[0]\n",
    "\n",
    "        std = np.std(np.array(tree_predictions), axis=0)[0]\n",
    "\n",
    "        mae_ = (y_test - mean)**2 / len(test_index)\n",
    "        RF_mae += mae_\n",
    "        \n",
    "    return RF_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing seed = 0\n",
      "Finished seed\n",
      "initializing seed = 1\n",
      "Finished seed\n",
      "initializing seed = 2\n",
      "Finished seed\n",
      "initializing seed = 3\n",
      "Finished seed\n",
      "initializing seed = 4\n",
      "Finished seed\n",
      "initializing seed = 5\n",
      "Finished seed\n",
      "initializing seed = 6\n",
      "Finished seed\n",
      "initializing seed = 7\n",
      "Finished seed\n",
      "initializing seed = 8\n",
      "Finished seed\n",
      "initializing seed = 9\n",
      "Finished seed\n",
      "initializing seed = 10\n",
      "Finished seed\n",
      "initializing seed = 11\n",
      "Finished seed\n",
      "initializing seed = 12\n",
      "Finished seed\n",
      "initializing seed = 13\n",
      "Finished seed\n",
      "initializing seed = 14\n",
      "Finished seed\n",
      "initializing seed = 15\n",
      "Finished seed\n",
      "initializing seed = 16\n",
      "Finished seed\n",
      "initializing seed = 17\n",
      "Finished seed\n",
      "initializing seed = 18\n",
      "Finished seed\n",
      "initializing seed = 19\n",
      "Finished seed\n",
      "initializing seed = 20\n",
      "Finished seed\n",
      "initializing seed = 21\n",
      "Finished seed\n",
      "initializing seed = 22\n",
      "Finished seed\n",
      "initializing seed = 23\n",
      "Finished seed\n",
      "initializing seed = 24\n",
      "Finished seed\n",
      "initializing seed = 25\n",
      "Finished seed\n",
      "initializing seed = 26\n",
      "Finished seed\n",
      "initializing seed = 27\n",
      "Finished seed\n",
      "initializing seed = 28\n",
      "Finished seed\n",
      "initializing seed = 29\n",
      "Finished seed\n",
      "initializing seed = 30\n",
      "Finished seed\n",
      "initializing seed = 31\n",
      "Finished seed\n",
      "initializing seed = 32\n",
      "Finished seed\n",
      "initializing seed = 33\n",
      "Finished seed\n",
      "initializing seed = 34\n",
      "Finished seed\n",
      "initializing seed = 35\n",
      "Finished seed\n",
      "initializing seed = 36\n",
      "Finished seed\n",
      "initializing seed = 37\n",
      "Finished seed\n",
      "initializing seed = 38\n",
      "Finished seed\n",
      "initializing seed = 39\n",
      "Finished seed\n",
      "initializing seed = 40\n",
      "Finished seed\n",
      "initializing seed = 41\n",
      "Finished seed\n",
      "initializing seed = 42\n",
      "Finished seed\n",
      "initializing seed = 43\n",
      "Finished seed\n",
      "initializing seed = 44\n",
      "Finished seed\n",
      "initializing seed = 45\n",
      "Finished seed\n",
      "initializing seed = 46\n",
      "Finished seed\n",
      "initializing seed = 47\n",
      "Finished seed\n",
      "initializing seed = 48\n",
      "Finished seed\n",
      "initializing seed = 49\n",
      "Finished seed\n"
     ]
    }
   ],
   "source": [
    "index_collection = []\n",
    "X_collection = []\n",
    "y_collection = []\n",
    "TopPercent_collection = []\n",
    "MAE_collection = []\n",
    "\n",
    "\n",
    "for s in seed_list:\n",
    "    print('initializing seed = ' +str(seed_list.index(s)))\n",
    "    random.seed(s)\n",
    "    \n",
    "    indices = list(np.arange(len(X_run)))\n",
    "    \n",
    "    \n",
    "    X_top = []\n",
    "    y_top = []\n",
    "    for i in top_indices:\n",
    "        X_top.append(X_feature[i])\n",
    "        y_top.append(y[i])\n",
    "        \n",
    "    index_learn = indices.copy()\n",
    "    \n",
    "    index_ = random.sample(index_learn, n_initial)\n",
    "    X_ = []\n",
    "    y_ = []\n",
    "    TopPercent_ = []\n",
    "    MAE_ = []\n",
    "    for i in index_:\n",
    "        X_.append(X_feature[i])\n",
    "        y_.append(y[i])\n",
    "        index_learn.remove(i)\n",
    "        \n",
    "    index_mae = indices.copy()\n",
    "    \n",
    "    test_index = random.sample(index_mae, n_test)\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for i in test_index:\n",
    "        X_test.append(X_feature[i])\n",
    "        y_test.append(y[i])\n",
    "        index_mae.remove(i)\n",
    "        \n",
    "    X_full = []\n",
    "    y_full = []    \n",
    "    for i in index_mae:\n",
    "        X_full.append(X_feature[i])\n",
    "        y_full.append(y[i])\n",
    "        \n",
    "    \n",
    "    \n",
    "    assert len(indices) == len(X_full) + len(X_test)\n",
    "    \n",
    "#     GP_full = GPy.models.GPRegression(X = np.array(X_full), \n",
    "#                                       Y = np.array([[i] for i in y_full]), \n",
    "#                                       kernel= Matern52_kernel,\n",
    "#                                       noise_var = 0.01\n",
    "#                                       )\n",
    "\n",
    "#     GP_full.optimize_restarts(num_restarts=10,\n",
    "#                               parallel = True,\n",
    "#                               robust = True,\n",
    "#                               optimizer = 'bfgs',\n",
    "#                               max_iters=100,\n",
    "#                               verbose = False)\n",
    "    \n",
    "    for i in np.arange(len(index_learn)):\n",
    "        \n",
    "        y_best = np.min(y_)\n",
    "        \n",
    "        RF_model = RandomForestRegressor(n_estimators= n_est)\n",
    "        RF_model.fit(X_, y_)\n",
    "        \n",
    "        next_index = None\n",
    "        max_ac = -10**10\n",
    "        for j in index_learn:\n",
    "            X_j = X_feature[j]\n",
    "            y_j = y[j]\n",
    "            \n",
    "            ac_value = EI(X_j, RF_model, y_best)\n",
    "            \n",
    "            if max_ac <= ac_value:\n",
    "                max_ac = ac_value\n",
    "                next_index = j\n",
    "                \n",
    "        X_.append(X_feature[next_index])\n",
    "        y_.append(y[next_index])\n",
    "        index_learn.remove(next_index)\n",
    "        index_.append(next_index)\n",
    "        \n",
    "        \n",
    "        mae_ = calc_MAE(test_index, RF_model)\n",
    "        MAE_.append(mae_)\n",
    "        TopPercent_.append(TopPercent(top_indices, index_))\n",
    "        \n",
    "\n",
    "\n",
    "    index_collection.append(index_)\n",
    "    X_collection.append(X_)\n",
    "    y_collection.append(y_)\n",
    "    TopPercent_collection.append(TopPercent_)\n",
    "    MAE_collection.append(MAE_)\n",
    "    \n",
    "    print('Finished seed')\n",
    "    \n",
    "    \n",
    "master = np.array([index_collection, X_collection, y_collection, TopPercent_collection, MAE_collection])\n",
    "np.save('STANDARD_RF_EI_master', master)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing seed = 0\n",
      "Finished seed\n",
      "initializing seed = 1\n",
      "Finished seed\n",
      "initializing seed = 2\n",
      "Finished seed\n",
      "initializing seed = 3\n",
      "Finished seed\n",
      "initializing seed = 4\n",
      "Finished seed\n",
      "initializing seed = 5\n",
      "Finished seed\n",
      "initializing seed = 6\n",
      "Finished seed\n",
      "initializing seed = 7\n",
      "Finished seed\n",
      "initializing seed = 8\n",
      "Finished seed\n",
      "initializing seed = 9\n",
      "Finished seed\n",
      "initializing seed = 10\n",
      "Finished seed\n",
      "initializing seed = 11\n",
      "Finished seed\n",
      "initializing seed = 12\n",
      "Finished seed\n",
      "initializing seed = 13\n",
      "Finished seed\n",
      "initializing seed = 14\n",
      "Finished seed\n",
      "initializing seed = 15\n",
      "Finished seed\n",
      "initializing seed = 16\n",
      "Finished seed\n",
      "initializing seed = 17\n",
      "Finished seed\n",
      "initializing seed = 18\n",
      "Finished seed\n",
      "initializing seed = 19\n",
      "Finished seed\n",
      "initializing seed = 20\n",
      "Finished seed\n",
      "initializing seed = 21\n",
      "Finished seed\n",
      "initializing seed = 22\n",
      "Finished seed\n",
      "initializing seed = 23\n",
      "Finished seed\n",
      "initializing seed = 24\n",
      "Finished seed\n",
      "initializing seed = 25\n",
      "Finished seed\n",
      "initializing seed = 26\n",
      "Finished seed\n",
      "initializing seed = 27\n",
      "Finished seed\n",
      "initializing seed = 28\n",
      "Finished seed\n",
      "initializing seed = 29\n",
      "Finished seed\n",
      "initializing seed = 30\n",
      "Finished seed\n",
      "initializing seed = 31\n",
      "Finished seed\n",
      "initializing seed = 32\n",
      "Finished seed\n",
      "initializing seed = 33\n",
      "Finished seed\n",
      "initializing seed = 34\n",
      "Finished seed\n",
      "initializing seed = 35\n",
      "Finished seed\n",
      "initializing seed = 36\n",
      "Finished seed\n",
      "initializing seed = 37\n",
      "Finished seed\n",
      "initializing seed = 38\n",
      "Finished seed\n",
      "initializing seed = 39\n",
      "Finished seed\n",
      "initializing seed = 40\n",
      "Finished seed\n",
      "initializing seed = 41\n",
      "Finished seed\n",
      "initializing seed = 42\n",
      "Finished seed\n",
      "initializing seed = 43\n",
      "Finished seed\n",
      "initializing seed = 44\n",
      "Finished seed\n",
      "initializing seed = 45\n",
      "Finished seed\n",
      "initializing seed = 46\n",
      "Finished seed\n",
      "initializing seed = 47\n",
      "Finished seed\n",
      "initializing seed = 48\n",
      "Finished seed\n",
      "initializing seed = 49\n",
      "Finished seed\n"
     ]
    }
   ],
   "source": [
    "index_collection = []\n",
    "X_collection = []\n",
    "y_collection = []\n",
    "TopPercent_collection = []\n",
    "MAE_collection = []\n",
    "\n",
    "\n",
    "for s in seed_list:\n",
    "    print('initializing seed = ' +str(seed_list.index(s)))\n",
    "    random.seed(s)\n",
    "    \n",
    "    indices = list(np.arange(len(X_run)))\n",
    "    \n",
    "    \n",
    "    X_top = []\n",
    "    y_top = []\n",
    "    for i in top_indices:\n",
    "        X_top.append(X_feature[i])\n",
    "        y_top.append(y[i])\n",
    "        \n",
    "    index_learn = indices.copy()\n",
    "    \n",
    "    index_ = random.sample(index_learn, n_initial)\n",
    "    X_ = []\n",
    "    y_ = []\n",
    "    TopPercent_ = []\n",
    "    MAE_ = []\n",
    "    for i in index_:\n",
    "        X_.append(X_feature[i])\n",
    "        y_.append(y[i])\n",
    "        index_learn.remove(i)\n",
    "        \n",
    "    index_mae = indices.copy()\n",
    "    \n",
    "    test_index = random.sample(index_mae, n_test)\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for i in test_index:\n",
    "        X_test.append(X_feature[i])\n",
    "        y_test.append(y[i])\n",
    "        index_mae.remove(i)\n",
    "        \n",
    "    X_full = []\n",
    "    y_full = []    \n",
    "    for i in index_mae:\n",
    "        X_full.append(X_feature[i])\n",
    "        y_full.append(y[i])\n",
    "        \n",
    "    \n",
    "    \n",
    "    assert len(indices) == len(X_full) + len(X_test)\n",
    "    \n",
    "#     GP_full = GPy.models.GPRegression(X = np.array(X_full), \n",
    "#                                       Y = np.array([[i] for i in y_full]), \n",
    "#                                       kernel= Matern52_kernel,\n",
    "#                                       noise_var = 0.01\n",
    "#                                       )\n",
    "\n",
    "#     GP_full.optimize_restarts(num_restarts=10,\n",
    "#                               parallel = True,\n",
    "#                               robust = True,\n",
    "#                               optimizer = 'bfgs',\n",
    "#                               max_iters=100,\n",
    "#                               verbose = False)\n",
    "    \n",
    "    for i in np.arange(len(index_learn)):\n",
    "        \n",
    "        y_best = np.min(y_)\n",
    "        \n",
    "        RF_model = RandomForestRegressor(n_estimators = n_est)\n",
    "        RF_model.fit(X_, y_)\n",
    "        \n",
    "        next_index = None\n",
    "        max_ac = -10**10\n",
    "        for j in index_learn:\n",
    "            X_j = X_feature[j]\n",
    "            y_j = y[j]\n",
    "            \n",
    "            ac_value = LCB(X_j, RF_model)\n",
    "            \n",
    "            if max_ac <= ac_value:\n",
    "                max_ac = ac_value\n",
    "                next_index = j\n",
    "                \n",
    "        X_.append(X_feature[next_index])\n",
    "        y_.append(y[next_index])\n",
    "        index_learn.remove(next_index)\n",
    "        index_.append(next_index)\n",
    "        \n",
    "        \n",
    "        mae_ = calc_MAE(test_index, RF_model)\n",
    "        MAE_.append(mae_)\n",
    "        TopPercent_.append(TopPercent(top_indices, index_))\n",
    "        \n",
    "\n",
    "\n",
    "    index_collection.append(index_)\n",
    "    X_collection.append(X_)\n",
    "    y_collection.append(y_)\n",
    "    TopPercent_collection.append(TopPercent_)\n",
    "    MAE_collection.append(MAE_)\n",
    "    \n",
    "    print('Finished seed')\n",
    "    \n",
    "    \n",
    "master = np.array([index_collection, X_collection, y_collection, TopPercent_collection, MAE_collection])\n",
    "np.save('STANDARD_RF_LCB7525_master', master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing seed = 0\n",
      "Finished seed\n",
      "initializing seed = 1\n",
      "Finished seed\n",
      "initializing seed = 2\n",
      "Finished seed\n",
      "initializing seed = 3\n",
      "Finished seed\n",
      "initializing seed = 4\n",
      "Finished seed\n",
      "initializing seed = 5\n",
      "Finished seed\n",
      "initializing seed = 6\n",
      "Finished seed\n",
      "initializing seed = 7\n",
      "Finished seed\n",
      "initializing seed = 8\n",
      "Finished seed\n",
      "initializing seed = 9\n",
      "Finished seed\n",
      "initializing seed = 10\n",
      "Finished seed\n",
      "initializing seed = 11\n",
      "Finished seed\n",
      "initializing seed = 12\n",
      "Finished seed\n",
      "initializing seed = 13\n",
      "Finished seed\n",
      "initializing seed = 14\n",
      "Finished seed\n",
      "initializing seed = 15\n",
      "Finished seed\n",
      "initializing seed = 16\n",
      "Finished seed\n",
      "initializing seed = 17\n",
      "Finished seed\n",
      "initializing seed = 18\n",
      "Finished seed\n",
      "initializing seed = 19\n",
      "Finished seed\n",
      "initializing seed = 20\n",
      "Finished seed\n",
      "initializing seed = 21\n",
      "Finished seed\n",
      "initializing seed = 22\n",
      "Finished seed\n",
      "initializing seed = 23\n",
      "Finished seed\n",
      "initializing seed = 24\n",
      "Finished seed\n"
     ]
    }
   ],
   "source": [
    "index_collection = []\n",
    "X_collection = []\n",
    "y_collection = []\n",
    "TopPercent_collection = []\n",
    "MAE_collection = []\n",
    "\n",
    "\n",
    "for s in seed_list:\n",
    "    print('initializing seed = ' +str(seed_list.index(s)))\n",
    "    random.seed(s)\n",
    "    \n",
    "    indices = list(np.arange(len(X_run)))\n",
    "    \n",
    "    \n",
    "    X_top = []\n",
    "    y_top = []\n",
    "    for i in top_indices:\n",
    "        X_top.append(X_feature[i])\n",
    "        y_top.append(y[i])\n",
    "        \n",
    "    index_learn = indices.copy()\n",
    "    \n",
    "    index_ = random.sample(index_learn, n_initial)\n",
    "    X_ = []\n",
    "    y_ = []\n",
    "    TopPercent_ = []\n",
    "    MAE_ = []\n",
    "    for i in index_:\n",
    "        X_.append(X_feature[i])\n",
    "        y_.append(y[i])\n",
    "        index_learn.remove(i)\n",
    "        \n",
    "    index_mae = indices.copy()\n",
    "    \n",
    "    test_index = random.sample(index_mae, n_test)\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for i in test_index:\n",
    "        X_test.append(X_feature[i])\n",
    "        y_test.append(y[i])\n",
    "        index_mae.remove(i)\n",
    "        \n",
    "    X_full = []\n",
    "    y_full = []    \n",
    "    for i in index_mae:\n",
    "        X_full.append(X_feature[i])\n",
    "        y_full.append(y[i])\n",
    "        \n",
    "    \n",
    "    \n",
    "    assert len(indices) == len(X_full) + len(X_test)\n",
    "    \n",
    "#     GP_full = GPy.models.GPRegression(X = np.array(X_full), \n",
    "#                                       Y = np.array([[i] for i in y_full]), \n",
    "#                                       kernel= Matern52_kernel,\n",
    "#                                       noise_var = 0.01\n",
    "#                                       )\n",
    "\n",
    "#     GP_full.optimize_restarts(num_restarts=10,\n",
    "#                               parallel = True,\n",
    "#                               robust = True,\n",
    "#                               optimizer = 'bfgs',\n",
    "#                               max_iters=100,\n",
    "#                               verbose = False)\n",
    "    \n",
    "    for i in np.arange(len(index_learn)):\n",
    "        \n",
    "        y_best = np.min(y_)\n",
    "        \n",
    "        RF_model = RandomForestRegressor(n_estimators= n_est)\n",
    "        RF_model.fit(X_, y_)\n",
    "        \n",
    "        next_index = None\n",
    "        max_ac = -10**10\n",
    "        for j in index_learn:\n",
    "            X_j = X_feature[j]\n",
    "            y_j = y[j]\n",
    "            \n",
    "            ac_value = MPI(X_j, RF_model, y_best)\n",
    "            \n",
    "            if max_ac <= ac_value:\n",
    "                max_ac = ac_value\n",
    "                next_index = j\n",
    "                \n",
    "        X_.append(X_feature[next_index])\n",
    "        y_.append(y[next_index])\n",
    "        index_learn.remove(next_index)\n",
    "        index_.append(next_index)\n",
    "        \n",
    "        \n",
    "        mae_ = calc_MAE(test_index, RF_model)\n",
    "        MAE_.append(mae_)\n",
    "        TopPercent_.append(TopPercent(top_indices, index_))\n",
    "        \n",
    "\n",
    "\n",
    "    index_collection.append(index_)\n",
    "    X_collection.append(X_)\n",
    "    y_collection.append(y_)\n",
    "    TopPercent_collection.append(TopPercent_)\n",
    "    MAE_collection.append(MAE_)\n",
    "    \n",
    "    print('Finished seed')\n",
    "    \n",
    "    \n",
    "master = np.array([index_collection, X_collection, y_collection, TopPercent_collection, MAE_collection])\n",
    "np.save('STANDARD_RF_MPI_master', master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing seed = 0\n",
      "Finished seed\n",
      "initializing seed = 1\n",
      "Finished seed\n",
      "initializing seed = 2\n",
      "Finished seed\n",
      "initializing seed = 3\n",
      "Finished seed\n",
      "initializing seed = 4\n",
      "Finished seed\n",
      "initializing seed = 5\n",
      "Finished seed\n",
      "initializing seed = 6\n",
      "Finished seed\n",
      "initializing seed = 7\n",
      "Finished seed\n",
      "initializing seed = 8\n",
      "Finished seed\n",
      "initializing seed = 9\n",
      "Finished seed\n",
      "initializing seed = 10\n",
      "Finished seed\n",
      "initializing seed = 11\n",
      "Finished seed\n",
      "initializing seed = 12\n",
      "Finished seed\n",
      "initializing seed = 13\n",
      "Finished seed\n",
      "initializing seed = 14\n",
      "Finished seed\n",
      "initializing seed = 15\n",
      "Finished seed\n",
      "initializing seed = 16\n",
      "Finished seed\n",
      "initializing seed = 17\n",
      "Finished seed\n",
      "initializing seed = 18\n",
      "Finished seed\n",
      "initializing seed = 19\n",
      "Finished seed\n",
      "initializing seed = 20\n",
      "Finished seed\n",
      "initializing seed = 21\n",
      "Finished seed\n",
      "initializing seed = 22\n",
      "Finished seed\n",
      "initializing seed = 23\n",
      "Finished seed\n",
      "initializing seed = 24\n",
      "Finished seed\n"
     ]
    }
   ],
   "source": [
    "index_collection = []\n",
    "X_collection = []\n",
    "y_collection = []\n",
    "TopPercent_collection = []\n",
    "MAE_collection = []\n",
    "\n",
    "\n",
    "for s in seed_list:\n",
    "    print('initializing seed = ' +str(seed_list.index(s)))\n",
    "    random.seed(s)\n",
    "    \n",
    "    indices = list(np.arange(len(X_run)))\n",
    "    \n",
    "    \n",
    "    X_top = []\n",
    "    y_top = []\n",
    "    for i in top_indices:\n",
    "        X_top.append(X_feature[i])\n",
    "        y_top.append(y[i])\n",
    "        \n",
    "    index_learn = indices.copy()\n",
    "    \n",
    "    index_ = random.sample(index_learn, n_initial)\n",
    "    X_ = []\n",
    "    y_ = []\n",
    "    TopPercent_ = []\n",
    "    MAE_ = []\n",
    "    for i in index_:\n",
    "        X_.append(X_feature[i])\n",
    "        y_.append(y[i])\n",
    "        index_learn.remove(i)\n",
    "        \n",
    "    index_mae = indices.copy()\n",
    "    \n",
    "    test_index = random.sample(index_mae, n_test)\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for i in test_index:\n",
    "        X_test.append(X_feature[i])\n",
    "        y_test.append(y[i])\n",
    "        index_mae.remove(i)\n",
    "        \n",
    "    X_full = []\n",
    "    y_full = []    \n",
    "    for i in index_mae:\n",
    "        X_full.append(X_feature[i])\n",
    "        y_full.append(y[i])\n",
    "        \n",
    "    \n",
    "    \n",
    "    assert len(indices) == len(X_full) + len(X_test)\n",
    "    \n",
    "#     GP_full = GPy.models.GPRegression(X = np.array(X_full), \n",
    "#                                       Y = np.array([[i] for i in y_full]), \n",
    "#                                       kernel= Matern52_kernel,\n",
    "#                                       noise_var = 0.01\n",
    "#                                       )\n",
    "\n",
    "#     GP_full.optimize_restarts(num_restarts=10,\n",
    "#                               parallel = True,\n",
    "#                               robust = True,\n",
    "#                               optimizer = 'bfgs',\n",
    "#                               max_iters=100,\n",
    "#                               verbose = False)\n",
    "    \n",
    "    for i in np.arange(len(index_learn)):\n",
    "        \n",
    "        y_best = np.min(y_)\n",
    "        \n",
    "        RF_model = RandomForestRegressor(n_estimators= n_est)\n",
    "        RF_model.fit(X_, y_)\n",
    "        \n",
    "        next_index = (random.sample(index_learn, 1))[0]\n",
    "                \n",
    "        X_.append(X_feature[next_index])\n",
    "        y_.append(y[next_index])\n",
    "        index_learn.remove(next_index)\n",
    "        index_.append(next_index)\n",
    "        \n",
    "        \n",
    "        mae_ = calc_MAE(test_index, RF_model)\n",
    "        MAE_.append(mae_)\n",
    "        TopPercent_.append(TopPercent(top_indices, index_))\n",
    "        \n",
    "\n",
    "\n",
    "    index_collection.append(index_)\n",
    "    X_collection.append(X_)\n",
    "    y_collection.append(y_)\n",
    "    TopPercent_collection.append(TopPercent_)\n",
    "    MAE_collection.append(MAE_)\n",
    "    \n",
    "    print('Finished seed')\n",
    "    \n",
    "    \n",
    "master = np.array([index_collection, X_collection, y_collection, TopPercent_collection, MAE_collection])\n",
    "np.save('STANDARD_RF_RS_master', master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "# from sklearn.gaussian_process.kernels import (RBF, Matern, RationalQuadratic,\n",
    "#                                               ExpSineSquared, DotProduct,\n",
    "#                                               ConstantKernel)\n",
    "\n",
    "# kernels = [1.0 * RBF(length_scale=1.0, length_scale_bounds=(1e-1, 10.0)),\n",
    "#            1.0 * RationalQuadratic(length_scale=1.0, alpha=0.1),\n",
    "#            1.0 * ExpSineSquared(length_scale=1.0, periodicity=3.0,length_scale_bounds=(0.1, 10.0), periodicity_bounds=(1.0, 10.0)),\n",
    "#            ConstantKernel(0.1, (0.01, 10.0))* (DotProduct(sigma_0=1.0, sigma_0_bounds=(0.1, 10.0)) ** 2),\n",
    "#            1.0 * Matern(length_scale=1.0, length_scale_bounds=(1e-1, 10.0), nu=1.5)]\n",
    "\n",
    "# model = GaussianProcessRegressor(alpha = 1e-10, \n",
    "#                                  kernel = kernels[0],\n",
    "#                                  optimizer = 'fmin_l_bfgs_b', \n",
    "#                                  n_restarts_optimizer = 1, \n",
    "#                                  random_state=0,\n",
    "#                                  normalize_y=True)\n",
    "\n",
    "# # feature order: ['CsPbI', 'MAPbI', 'FAPbI']\n",
    "# model.fit(X_feature, X_instability)\n",
    "\n",
    "# Why these models from sklearn don't work well, I'm confused..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
