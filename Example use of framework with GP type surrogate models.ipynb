{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import GPyOpt\n",
    "import GPy\n",
    "import os\n",
    "import matplotlib as mpl\n",
    "import matplotlib.tri as tri\n",
    "import ternary\n",
    "import pickle\n",
    "import datetime\n",
    "from collections import Counter\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn import preprocessing\n",
    "import pyDOE\n",
    "import random\n",
    "from scipy.stats import norm\n",
    "import time\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load materials dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>theta</th>\n",
       "      <th>r</th>\n",
       "      <th>t</th>\n",
       "      <th>toughness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.144667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.607561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.144338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.70</td>\n",
       "      <td>3.642738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.748405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>12</td>\n",
       "      <td>200</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.358975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>12</td>\n",
       "      <td>200</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.40</td>\n",
       "      <td>3.196306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>12</td>\n",
       "      <td>200</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.70</td>\n",
       "      <td>36.104187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798</th>\n",
       "      <td>12</td>\n",
       "      <td>200</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.313487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799</th>\n",
       "      <td>12</td>\n",
       "      <td>200</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.069728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1800 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       n  theta    r     t  toughness\n",
       "0      6      0  1.5  0.70   1.144667\n",
       "1      6      0  1.5  1.05   1.607561\n",
       "2      6      0  1.5  1.40   1.144338\n",
       "3      6      0  1.7  0.70   3.642738\n",
       "4      6      0  1.7  1.05   3.748405\n",
       "...   ..    ...  ...   ...        ...\n",
       "1795  12    200  2.3  1.05   1.358975\n",
       "1796  12    200  2.3  1.40   3.196306\n",
       "1797  12    200  2.5  0.70  36.104187\n",
       "1798  12    200  2.5  1.05   1.313487\n",
       "1799  12    200  2.5  1.40   1.069728\n",
       "\n",
       "[1800 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# go to directory where datasets reside\n",
    "# load a dataset\n",
    "# dataset names = ['Crossed barrel', 'Perovskite', 'AgNP', 'P3HT', 'AutoAM']\n",
    "dataset_name = 'Crossed barrel'\n",
    "raw_dataset = pd.read_csv(dataset_name + '_dataset.csv')\n",
    "raw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['n', 'theta', 'r', 't']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_name = list(raw_dataset.columns)[:-1]\n",
    "feature_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'toughness'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objective_name = list(raw_dataset.columns)[-1]\n",
    "objective_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formulate optimization as global minimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>theta</th>\n",
       "      <th>r</th>\n",
       "      <th>t</th>\n",
       "      <th>toughness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.70</td>\n",
       "      <td>-1.144667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.05</td>\n",
       "      <td>-1.607561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.40</td>\n",
       "      <td>-1.144338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.70</td>\n",
       "      <td>-3.642738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.05</td>\n",
       "      <td>-3.748405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>12</td>\n",
       "      <td>200</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.05</td>\n",
       "      <td>-1.358975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>12</td>\n",
       "      <td>200</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.40</td>\n",
       "      <td>-3.196306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>12</td>\n",
       "      <td>200</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.70</td>\n",
       "      <td>-36.104187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798</th>\n",
       "      <td>12</td>\n",
       "      <td>200</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.05</td>\n",
       "      <td>-1.313487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799</th>\n",
       "      <td>12</td>\n",
       "      <td>200</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.40</td>\n",
       "      <td>-1.069728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1800 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       n  theta    r     t  toughness\n",
       "0      6      0  1.5  0.70  -1.144667\n",
       "1      6      0  1.5  1.05  -1.607561\n",
       "2      6      0  1.5  1.40  -1.144338\n",
       "3      6      0  1.7  0.70  -3.642738\n",
       "4      6      0  1.7  1.05  -3.748405\n",
       "...   ..    ...  ...   ...        ...\n",
       "1795  12    200  2.3  1.05  -1.358975\n",
       "1796  12    200  2.3  1.40  -3.196306\n",
       "1797  12    200  2.5  0.70 -36.104187\n",
       "1798  12    200  2.5  1.05  -1.313487\n",
       "1799  12    200  2.5  1.40  -1.069728\n",
       "\n",
       "[1800 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for P3HT/CNT, Crossed barrel, AutoAM, their original goals were to maximize objective value.\n",
    "# here, we add negative sign to all of its objective values here \n",
    "# because default BO in the framework below aims for global minimization\n",
    "# only P3HT/CNT, Crossed barrel, AutoAM need this line; Perovskite and AgNP do not need this line.\n",
    "ds = copy.deepcopy(raw_dataset) \n",
    "ds[objective_name] = -raw_dataset[objective_name].values\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process dataset for pool-based active learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>theta</th>\n",
       "      <th>r</th>\n",
       "      <th>t</th>\n",
       "      <th>toughness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.70</td>\n",
       "      <td>-1.135453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.05</td>\n",
       "      <td>-1.406492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.40</td>\n",
       "      <td>-1.343498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.70</td>\n",
       "      <td>-3.102525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.05</td>\n",
       "      <td>-3.196597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>12</td>\n",
       "      <td>200</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.05</td>\n",
       "      <td>-4.775444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>12</td>\n",
       "      <td>200</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.40</td>\n",
       "      <td>-1.997221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>12</td>\n",
       "      <td>200</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.70</td>\n",
       "      <td>-24.956734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>12</td>\n",
       "      <td>200</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.05</td>\n",
       "      <td>-1.360121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>12</td>\n",
       "      <td>200</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.40</td>\n",
       "      <td>-1.337742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      n  theta    r     t  toughness\n",
       "0     6      0  1.5  0.70  -1.135453\n",
       "1     6      0  1.5  1.05  -1.406492\n",
       "2     6      0  1.5  1.40  -1.343498\n",
       "3     6      0  1.7  0.70  -3.102525\n",
       "4     6      0  1.7  1.05  -3.196597\n",
       "..   ..    ...  ...   ...        ...\n",
       "595  12    200  2.3  1.05  -4.775444\n",
       "596  12    200  2.3  1.40  -1.997221\n",
       "597  12    200  2.5  0.70 -24.956734\n",
       "598  12    200  2.5  1.05  -1.360121\n",
       "599  12    200  2.5  1.40  -1.337742\n",
       "\n",
       "[600 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for some datasets, each input feature x could have been evaluated more than once.\n",
    "# to perform pool-based active learning, we need to group the data by unique input feature x value. \n",
    "# for each unique x in design space, we only keep the average of all evaluations there as its objective value\n",
    "ds_grouped = ds.groupby(feature_name)[objective_name].agg(lambda x: x.unique().mean())\n",
    "ds_grouped = (ds_grouped.to_frame()).reset_index()\n",
    "ds_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize input features and objective values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>theta</th>\n",
       "      <th>r</th>\n",
       "      <th>t</th>\n",
       "      <th>toughness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.341641</td>\n",
       "      <td>-1.53393</td>\n",
       "      <td>-1.565561</td>\n",
       "      <td>-1.224745</td>\n",
       "      <td>1.310884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.341641</td>\n",
       "      <td>-1.53393</td>\n",
       "      <td>-1.565561</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.285839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.341641</td>\n",
       "      <td>-1.53393</td>\n",
       "      <td>-1.565561</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.291659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.341641</td>\n",
       "      <td>-1.53393</td>\n",
       "      <td>-0.939336</td>\n",
       "      <td>-1.224745</td>\n",
       "      <td>1.129119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.341641</td>\n",
       "      <td>-1.53393</td>\n",
       "      <td>-0.939336</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.120426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>1.341641</td>\n",
       "      <td>1.53393</td>\n",
       "      <td>0.939336</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>1.341641</td>\n",
       "      <td>1.53393</td>\n",
       "      <td>0.939336</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.231253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>1.341641</td>\n",
       "      <td>1.53393</td>\n",
       "      <td>1.565561</td>\n",
       "      <td>-1.224745</td>\n",
       "      <td>-0.890291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>1.341641</td>\n",
       "      <td>1.53393</td>\n",
       "      <td>1.565561</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.290123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>1.341641</td>\n",
       "      <td>1.53393</td>\n",
       "      <td>1.565561</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.292191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            n    theta         r         t  toughness\n",
       "0   -1.341641 -1.53393 -1.565561 -1.224745   1.310884\n",
       "1   -1.341641 -1.53393 -1.565561  0.000000   1.285839\n",
       "2   -1.341641 -1.53393 -1.565561  1.224745   1.291659\n",
       "3   -1.341641 -1.53393 -0.939336 -1.224745   1.129119\n",
       "4   -1.341641 -1.53393 -0.939336  0.000000   1.120426\n",
       "..        ...      ...       ...       ...        ...\n",
       "595  1.341641  1.53393  0.939336  0.000000   0.974535\n",
       "596  1.341641  1.53393  0.939336  1.224745   1.231253\n",
       "597  1.341641  1.53393  1.565561 -1.224745  -0.890291\n",
       "598  1.341641  1.53393  1.565561  0.000000   1.290123\n",
       "599  1.341641  1.53393  1.565561  1.224745   1.292191\n",
       "\n",
       "[600 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_scaler = preprocessing.StandardScaler()\n",
    "ds_normalized_values = s_scaler.fit_transform(ds_grouped[list(raw_dataset.columns)].values)\n",
    "ds_normalized = pd.DataFrame(ds_normalized_values, columns = list(raw_dataset.columns))\n",
    "ds_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n"
     ]
    }
   ],
   "source": [
    "# these are the input feature x and objective value y used in framework\n",
    "X_feature = ds_normalized[feature_name].values\n",
    "\n",
    "y = np.array(ds_normalized[objective_name].values)\n",
    "\n",
    "assert len(ds_normalized) == len(X_feature) == len(y)\n",
    "\n",
    "# total number of data in set\n",
    "N = len(ds_normalized)\n",
    "print(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking Framework parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here are some parameters of the framework, feel free to modify for your own purposes\n",
    "\n",
    "# number of ensembles. in the paper n_ensemble = 50.\n",
    "n_ensemble = 50\n",
    "# number of initial experiments\n",
    "n_initial = 2\n",
    "# number of top candidates, currently using top 5% of total dataset size\n",
    "n_top = int(math.ceil(len(y) * 0.05))\n",
    "# the top candidates and their indicies\n",
    "top_indices = list(ds_normalized.sort_values(objective_name).head(n_top).index)\n",
    "\n",
    "# random seeds used to distinguish between different ensembles\n",
    "# there are 300 of them, but only first n_ensemble are used\n",
    "seed_list = [4295, 8508, 326, 3135, 1549, 2528, 1274, 6545, 5971, 6269, 2422, 4287, 9320, 4932, 951, 4304, 1745, 5956, 7620, 4545, 6003, 9885, 5548, 9477, 30, 8992, 7559, 5034, 9071, 6437, 3389, 9816, 8617, 3712, 3626, 1660, 3309, 2427, 9872, 938, 5156, 7409, 7672, 3411, 3559, 9966, 7331, 8273, 8484, 5127, 2260, 6054, 5205, 311, 6056, 9456, 928, 6424, 7438, 8701, 8634, 4002, 6634, 8102, 8503, 1540, 9254, 7972, 7737, 3410, 4052, 8640, 9659, 8093, 7076, 7268, 2046, 7492, 3103, 3034, 7874, 5438, 4297, 291, 5436, 9021, 3711, 7837, 9188, 2036, 8013, 6188, 3734, 187, 1438, 1061, 674, 777, 7231, 7096, 3360, 4278, 5817, 5514, 3442, 6805, 6750, 8548, 9751, 3526, 9969, 8979, 1526, 1551, 2058, 6325, 1237, 5917, 5821, 9946, 5049, 654, 7750, 5149, 3545, 9165, 2837, 5621, 6501, 595, 3181, 1747, 4405, 4480, 4282, 9262, 6219, 3960, 4999, 1495, 6007, 9642, 3902, 3133, 1085, 3278, 1104, 5939, 7153, 971, 8733, 3785, 9056, 2020, 7249, 5021, 3384, 8740, 4593, 7869, 9941, 8813, 3688, 8139, 6436, 3742, 5503, 1587, 4766, 9846, 9117, 7001, 4853, 9346, 4927, 8480, 5298, 4753, 1151, 9768, 5405, 6196, 5721, 3419, 8090, 8166, 7834, 1480, 1150, 9002, 1134, 2237, 3995, 2029, 5336, 7050, 6857, 8794, 1754, 1184, 3558, 658, 6804, 8750, 5088, 1136, 626, 8462, 5203, 3196, 979, 7419, 1162, 5451, 6492, 1562, 8145, 8937, 8764, 4174, 7639, 8902, 7003, 765, 1554, 6135, 1689, 9530, 1398, 2273, 7925, 5948, 1036, 868, 4617, 1203, 7680, 7, 93, 3128, 5694, 6979, 7136, 8084, 5770, 9301, 1599, 737, 7018, 3774, 9843, 2296, 2287, 9875, 2349, 2469, 8941, 4973, 3798, 54, 2938, 4665, 3942, 3951, 9400, 3094, 2248, 3376, 1926, 5180, 1773, 3681, 1808, 350, 6669, 826, 539, 5313, 6193, 5752, 9370, 2782, 8399, 4881, 3166, 4906, 5829, 4827, 29, 6899, 9012, 6986, 4175, 1035, 8320, 7802, 3777, 6340, 7798, 7705]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GP's surrogate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GP_pred(X, GP_model):\n",
    "    X = X.reshape([1,X_feature.shape[1]])\n",
    "    \n",
    "    mean, std = GP_model.predict(X)[0][0][0], GP_model.predict(X)[1][0][0]\n",
    "    return mean, std\n",
    "    \n",
    "\n",
    "# expected improvement\n",
    "def EI(X, GP_model, y_best):\n",
    "    xi = 0\n",
    "#     can also use 0.01\n",
    "    \n",
    "    mean, std = GP_pred(X, GP_model)\n",
    "\n",
    "    z = (y_best - mean - xi)/std\n",
    "    return (y_best - mean - xi) * norm.cdf(z) + std * norm.pdf(z)\n",
    "\n",
    "# lower confidence bound\n",
    "def LCB(X, GP_model, ratio):\n",
    "    \n",
    "    mean, std = GP_pred(X, GP_model)\n",
    "    \n",
    "    return - ratio * mean + std\n",
    "\n",
    "# probability of improvement\n",
    "def PI(X, GP_model, y_best):\n",
    "    xi = 0\n",
    "#     can also use 0.01\n",
    "    mean, std = GP_pred(X, GP_model)\n",
    "    \n",
    "    z = (y_best - mean - xi)/std\n",
    "    return norm.cdf(z)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# isotropic and anisotropic kernels for GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if use isotropic kernels, ARD_ = False\n",
    "# if use anisotropic kernels, ARD_ = True\n",
    "\n",
    "ARD_ = True\n",
    "\n",
    "Bias_kernel = GPy.kern.Bias(X_feature.shape[1], variance=1.)\n",
    "\n",
    "Matern52_kernel = GPy.kern.Matern52(X_feature.shape[1], variance=1., ARD=ARD_) + Bias_kernel\n",
    "Matern32_kernel = GPy.kern.Matern32(X_feature.shape[1], variance=1., ARD=ARD_) + Bias_kernel\n",
    "Matern12_kernel = GPy.kern.Exponential(X_feature.shape[1], variance=1., ARD=ARD_) + Bias_kernel\n",
    "RBF_kernel = GPy.kern.RBF(X_feature.shape[1], variance=1., ARD=ARD_) + Bias_kernel\n",
    "MLP_kernel = GPy.kern.MLP(X_feature.shape[1], variance=1., ARD=ARD_) + Bias_kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pool-based active learning framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing seed = 0\n",
      "Finished seed\n"
     ]
    }
   ],
   "source": [
    "# framework\n",
    "\n",
    "\n",
    "# good practice to keep check of time used\n",
    "start_time = time.time()\n",
    "\n",
    "# these will carry results along optimization sequence from all n_ensemble runs\n",
    "index_collection = []\n",
    "X_collection = []\n",
    "y_collection = []\n",
    "TopCount_collection = []\n",
    "\n",
    "\n",
    "\n",
    "for s in seed_list:\n",
    "    \n",
    "    if len(index_collection) == n_ensemble:\n",
    "        break\n",
    "    \n",
    "    print('initializing seed = ' +str(seed_list.index(s)))\n",
    "    random.seed(s)\n",
    "    \n",
    "    indices = list(np.arange(N))\n",
    "# index_learn is the pool of candidates to be examined\n",
    "    index_learn = indices.copy()\n",
    "# index_ is the list of candidates we have already observed\n",
    "#     adding in the initial experiments\n",
    "    index_ = random.sample(index_learn, n_initial)\n",
    "    \n",
    "#     list to store all observed good candidates' input feature X\n",
    "    X_ = []\n",
    "#     list to store all observed good candidates' objective value y\n",
    "    y_ = []\n",
    "#     number of top candidates found so far\n",
    "    c = 0\n",
    "#     list of cumulative number of top candidates found at each learning cycle\n",
    "    TopCount_ = []\n",
    "#     add the first n_initial experiments to collection\n",
    "    for i in index_:\n",
    "        X_.append(X_feature[i])\n",
    "        y_.append(y[i])\n",
    "        if i in top_indices:\n",
    "            c += 1\n",
    "        TopCount_.append(c)\n",
    "        index_learn.remove(i)\n",
    "           \n",
    "\n",
    "#     for each of the the rest of (N - n_initial) learning cycles\n",
    "#     this for loop ends when all candidates in pool are observed \n",
    "    for i in np.arange(len(index_learn)):\n",
    "        \n",
    "        y_best = np.min(y_)\n",
    "        \n",
    "        try:\n",
    "#             #TODO: select kernel for GP surrogate model\n",
    "            GP_learn = GPy.models.GPRegression(X = np.array(X_), \n",
    "                                               Y = np.array([[i] for i in y_]), \n",
    "                                               kernel= Matern32_kernel,\n",
    "                                               noise_var = 0.01\n",
    "                                              )\n",
    "\n",
    "            GP_learn.optimize_restarts(num_restarts=10,\n",
    "                                       parallel = True,\n",
    "                                       robust = True,\n",
    "                                       optimizer = 'bfgs',\n",
    "                                       max_iters=100,\n",
    "                                       verbose = False)\n",
    "        except:\n",
    "            break\n",
    "        \n",
    "#         by evaluating acquisition function values at candidates remaining in pool\n",
    "#         we choose candidate with larger acquisition function value to be observed next   \n",
    "        next_index = None\n",
    "        max_ac = -10**10\n",
    "        for j in index_learn:\n",
    "            X_j = X_feature[j]\n",
    "            y_j = y[j]\n",
    "#             #TODO: select Acquisiton Function for BO\n",
    "            ac_value = LCB(X_j, GP_learn, 1)\n",
    "            \n",
    "            if max_ac <= ac_value:\n",
    "                max_ac = ac_value\n",
    "                next_index = j\n",
    "                \n",
    "        \n",
    "                \n",
    "        X_.append(X_feature[next_index])\n",
    "        y_.append(y[next_index])\n",
    "        \n",
    "        \n",
    "        if next_index in top_indices:\n",
    "            c += 1\n",
    "        \n",
    "        TopCount_.append(c)\n",
    "        \n",
    "        index_learn.remove(next_index)\n",
    "        index_.append(next_index)        \n",
    "\n",
    "    assert len(index_) == N\n",
    "    \n",
    "    index_collection.append(index_)\n",
    "    X_collection.append(X_)\n",
    "    y_collection.append(y_)\n",
    "    TopCount_collection.append(TopCount_)\n",
    "    \n",
    "    \n",
    "    print('Finished seed')\n",
    "    \n",
    "total_time = time.time() - start_time\n",
    "\n",
    "master = np.array([index_collection, X_collection, y_collection, TopCount_collection, total_time])\n",
    "#  #TODO: name output file\n",
    "np.save('test_run', master)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
